{{ if .Values.spec.kubedescheduler.enabled -}}
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: kube-descheduler{{ .Values.spec.destination.clustername }}
  namespace: argocd
spec:
  syncPolicy:
    automated: # automated sync by default retries failed attempts 5 times with following delays between attempts ( 5s, 10s, 20s, 40s, 80s ); retry controlled using `retry` field.
      prune: true # Specifies if resources should be pruned during auto-syncing ( false by default ).
      selfHeal: true # Specifies if partial app sync should be executed when resources are changed only in target Kubernetes cluster and no git change detected ( false by default ).
      allowEmpty: false # Allows deleting all application resources during automatic syncing ( false by default ).
    syncOptions:     # Sync options which modifies sync behavior
      - Validate=false # disables resource validation (equivalent to 'kubectl apply --validate=false') ( true by default ).
      - CreateNamespace=true # Namespace Auto-Creation ensures that namespace specified as the application destination exists in the destination cluster.
      - PrunePropagationPolicy=foreground # Supported policies are background, foreground and orphan.
      - PruneLast=true # Allow the ability for resource pruning to happen as a final, implicit wave of a sync operation
    retry:
      limit: -1 # number of failed sync attempt retries; unlimited number of attempts if less than 0
      backoff:
        duration: 5s # the amount to back off. Default unit is seconds, but could also be a duration (e.g. "2m", "1h")
        factor: 2 # a factor to multiply the base duration after each failed retry
        maxDuration: 3m # the maximum amount of time allowed for the backoff strategy
  destination:
    namespace: {{ .Values.spec.destination.project }}
    server: {{ .Values.spec.destination.server }}
  project: {{ .Values.spec.destination.project }}
  source:
    chart: descheduler
    repoURL:   https://kubernetes-sigs.github.io/descheduler/
    targetRevision: 1.0.2
    helm:
      values: |
        # Default values for descheduler.
        # This is a YAML-formatted file.
        # Declare variables to be passed into your templates.

        cronJobApiVersion: "batch/v1beta1"
        image:
          repository: k8s.gcr.io/descheduler/descheduler
          # Overrides the image tag whose default is the chart version
          tag: ""
          pullPolicy: IfNotPresent

        imagePullSecrets: [ ]

        resources:
          requests:
            cpu: 10m
            memory: 256Mi
          # limits:
          #   cpu: 100m
          #   memory: 128Mi

        nameOverride: ""
        fullnameOverride: ""

        schedule: "*/2 * * * *"
        #startingDeadlineSeconds: 200
        #successfulJobsHistoryLimit: 1
        #failedJobsHistoryLimit: 1

        cmdOptions:
          v: 3
          # evict-local-storage-pods:
          # max-pods-to-evict-per-node: 10
          # node-selector: "key1=value1,key2=value2"

        deschedulerPolicy:
          strategies:
            RemoveDuplicates:
              enabled: false
            RemovePodsViolatingNodeTaints:
              enabled: true
            RemovePodsViolatingNodeAffinity:
              enabled: true
              params:
                nodeAffinityType:
                  - requiredDuringSchedulingIgnoredDuringExecution
            RemovePodsViolatingInterPodAntiAffinity:
              enabled: true
            LowNodeUtilization:
              enabled: true
              params:
                nodeResourceUtilizationThresholds:
                  thresholds:
                    cpu: 20
                    memory: 20
                    pods: 20
                  targetThresholds:
                    cpu: 50
                    memory: 50
                    pods: 50

        priorityClassName: system-cluster-critical

        nodeSelector: { }
        #  foo: bar

        rbac:
          # Specifies whether RBAC resources should be created
          create: true

        podSecurityPolicy:
          # Specifies whether PodSecurityPolicy should be created.
          create: true

        serviceAccount:
          # Specifies whether a ServiceAccount should be created
          create: true
          # The name of the ServiceAccount to use.
          # If not set and create is true, a name is generated using the fullname template
          name:

{{- end }}